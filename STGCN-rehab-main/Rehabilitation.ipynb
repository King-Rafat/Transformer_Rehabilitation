{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555c17f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from GCN.data_processing import Data_Loader\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image,ImageOps\n",
    "import torch.nn.functional as F\n",
    "from vidaug import augmentors as va\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from torch import einsum\n",
    "from argparse import ArgumentParser\n",
    "from core.models.curvenet_cls import CurveNet\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "random_seed = 420 #for reproducibility\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from torchsummary import summary\n",
    "import colorama\n",
    "from colorama import Fore, Back, Style\n",
    "colorama.init(autoreset=True)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2f2d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 19 19:31:20 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 526.86       Driver Version: 526.86       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   68C    P8     4W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c14413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, num_node):\n",
    "        self.num_node = num_node\n",
    "        self.AD, self.AD2, self.bias_mat_1, self.bias_mat_2 = self.normalize_adjacency()\n",
    "        \n",
    "    def normalize_adjacency(self):\n",
    "        self_link = [(i, i) for i in range(self.num_node)]\n",
    "#         print('self', self_link)\n",
    "        neighbor_1base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
    "                                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
    "                                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
    "                                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
    "                                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
    "        neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]\n",
    "#         print('neighbour: ', neighbor_link)\n",
    "        edge = self_link + neighbor_link\n",
    "#         print('Edge: ' ,edge)\n",
    "        A = np.zeros((self.num_node, self.num_node)) # adjacency matrix\n",
    "        print(A.shape)\n",
    "        for i, j in edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "        print(A)\n",
    "        A2 = np.zeros((self.num_node, self.num_node)) # second order adjacency matrix\n",
    "        for root in range(A.shape[1]):\n",
    "            for neighbour in range(A.shape[0]):\n",
    "                if A[root, neighbour] == 1:\n",
    "                    for neighbour_of_neigbour in range(A.shape[0]):\n",
    "                        if A[neighbour, neighbour_of_neigbour] == 1:\n",
    "                            A2[root,neighbour_of_neigbour] = 1  \n",
    "#         print(A2)\n",
    "        #AD = self.normalize(A)\n",
    "        #AD2 = self.normalize(A2)\n",
    "        bias_mat_1 = np.zeros(A.shape)\n",
    "        bias_mat_2 = np.zeros(A2.shape)\n",
    "        bias_mat_1 = np.where(A!=0, bias_mat_1, -1e9)\n",
    "        bias_mat_2 = np.where(A2!=0, A2, -1e9)\n",
    "        AD = A.astype('float32')\n",
    "        AD2 = A2.astype('float32')\n",
    "        bias_mat_1 = bias_mat_1.astype('float32')\n",
    "        bias_mat_2 = bias_mat_2.astype('float32')\n",
    "        AD = torch.tensor(AD)\n",
    "        AD2= torch.tensor(AD2)\n",
    "        bias_mat_1 = torch.tensor(bias_mat_1)\n",
    "        bias_mat_2 = torch.tensor(bias_mat_2)\n",
    "        return AD, AD2, bias_mat_1, bias_mat_2\n",
    "        \n",
    "    def normalize(self, adjacency):\n",
    "        rowsum = np.array(adjacency.sum(1))\n",
    "        r_inv = np.power(rowsum, -1).flatten()\n",
    "        r_inv[np.isinf(r_inv)] = 0\n",
    "        r_mat_inv = np.diag(r_inv)\n",
    "        normalize_adj = r_mat_inv.dot(adjacency)\n",
    "        normalize_adj = normalize_adj.astype('float32')\n",
    "        normalize_adj = torch.tensor(normalize_adj)   \n",
    "        return normalize_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc51fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(np.unique(train_y)))\n",
    "# print(np.unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75418ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_x))\n",
    "# print(len(train_y))\n",
    "# print(len(test_x))\n",
    "# print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2314d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca947bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753ec374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor(train_x)\n",
    "# x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003b1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        self.create_embedding_fn()\n",
    "\n",
    "    def create_embedding_fn(self):\n",
    "        embed_fns = []\n",
    "        d = self.kwargs['input_dims']\n",
    "        out_dim = 0\n",
    "        if self.kwargs['include_input']:\n",
    "            embed_fns.append(lambda x : x)\n",
    "            out_dim += d\n",
    "\n",
    "        max_freq = self.kwargs['max_freq_log2']\n",
    "        N_freqs = self.kwargs['num_freqs']\n",
    "\n",
    "        if self.kwargs['log_sampling']:\n",
    "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
    "        else:\n",
    "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
    "\n",
    "        for freq in freq_bands:\n",
    "            for p_fn in self.kwargs['periodic_fns']:\n",
    "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
    "                out_dim += d\n",
    "\n",
    "        self.embed_fns = embed_fns\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def embed(self, inputs):\n",
    "        normalized = torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
    "        return normalized\n",
    "    \n",
    "def get_embedder(multires = 10, i=0):\n",
    "    if i == -1:\n",
    "        return nn.Identity(), 1\n",
    "\n",
    "    embed_kwargs = {\n",
    "                'include_input' : True,\n",
    "                'input_dims' : 1,\n",
    "                'max_freq_log2' : multires-1,\n",
    "                'num_freqs' : multires,\n",
    "                'log_sampling' : True,\n",
    "                'periodic_fns' : [torch.sin, torch.cos],\n",
    "    }\n",
    "\n",
    "    embedder_obj = Embedder(**embed_kwargs)\n",
    "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
    "    return embed, embedder_obj.out_dim\n",
    "\n",
    "embeder = get_embedder()[0]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16783b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "# GELU -> Gaussian Error Linear Units\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class RemixerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        seq_len,\n",
    "        causal = False,\n",
    "        bias = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.causal = causal\n",
    "        self.proj_in = nn.Linear(dim, 2 * dim, bias = bias)\n",
    "        self.mixer = nn.Parameter(torch.randn(seq_len, seq_len))\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.))\n",
    "        self.proj_out = nn.Linear(dim, dim, bias = bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mixer, causal, device = self.mixer, self.causal, x.device\n",
    "        x, gate = self.proj_in(x).chunk(2, dim = -1)\n",
    "        x = F.gelu(gate) * x\n",
    "\n",
    "        if self.causal:\n",
    "            seq = x.shape[1]\n",
    "            mask_value = -torch.finfo(x.dtype).max\n",
    "            mask = torch.ones((seq, seq), device = device, dtype=torch.bool).triu(1)\n",
    "            mixer = mixer[:seq, :seq]\n",
    "            mixer = mixer.masked_fill(mask, mask_value)\n",
    "\n",
    "        mixer = mixer.softmax(dim = -1)\n",
    "        mixed = einsum('b n d, m n -> b m d', x, mixer)\n",
    "\n",
    "        alpha = self.alpha.sigmoid()\n",
    "        out = (x * mixed) * alpha + (x - mixed) * (1 - alpha)\n",
    "\n",
    "        return self.proj_out(out)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: `embeddings`, shape (batch, max_len, d_model)\n",
    "        Returns:\n",
    "            `encoder input`, shape (batch, max_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        # print(f'Attention:: {dim} - {heads} - {dim_head} - {dropout}')\n",
    "\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.pos_embedding = PositionalEncoding(dim,0.1,128)\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x += self.pos_embedding(x)\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        # print('\\n')\n",
    "        # print(f'Transformers:: {dim} - {depth} - {heads} - {dim_head} - {mlp_dim}')\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "                #PreNorm(dim, RemixerBlock(dim,17))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, swap = False):\n",
    "        if swap: # for the self.transformer(x,swap = True)\n",
    "            b, t, n , c = x.size() \n",
    "        for idx, (attn, ff) in enumerate(self.layers):\n",
    "            if swap: # for the self.transformer(x,swap = True)\n",
    "                if idx % 2 == 0:\n",
    "                    #* attention along with all timesteps(frames) for each point(landmark)\n",
    "                    x = rearrange(x, \"b t n c -> (b n) t c\")\n",
    "                else:\n",
    "                    #* attention to all points(landmarks) in each timestep(frame)\n",
    "                    x = rearrange(x, \"b t n c -> (b t) n c\")\n",
    "            x = attn(x) + x  # skip connections\n",
    "            x = ff(x) + x    # skip connections\n",
    "            \n",
    "            # Now return the input x to its original formation\n",
    "            if swap: # for the self.transformer(x,swap = True)\n",
    "                if idx % 2 == 0:\n",
    "                    x = rearrange(x, \"(b n) t c -> b t n c\", b = b)\n",
    "                else:\n",
    "                    x = rearrange(x, \"(b t) n c -> b t n c\", b = b)\n",
    "                \n",
    "        return x\n",
    "\n",
    "\n",
    "class TemporalModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TemporalModel,self).__init__()\n",
    "                \n",
    "        self.encoder  =  CurveNet() # curve aggregation, needed for Point Clouds Shape Analysis. \n",
    "        self.downsample = nn.Sequential(\n",
    "                            nn.Conv1d(120, 32, kernel_size=1, bias=False),\n",
    "                            nn.BatchNorm1d(32),\n",
    "                            # nn.Dropout(p=0.25), #* NEW\n",
    "                            #nn.ReLU(inplace=True),\n",
    "                            #nn.Conv1d(128, 32, kernel_size=1, bias=False),\n",
    "                            #nn.BatchNorm1d(32),\n",
    "                            )\n",
    "        \n",
    "        self.transformer = Transformer(256, 6, 4, 256//4, 256 * 2, 0.1)\n",
    "        self.time = Transformer(256, 3, 4, 256//4, 256 * 2, 0.1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256,1),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,t,n,c = x.size()\n",
    "    \n",
    "        x = rearrange(x, \"b t n c -> (b t) c n\")\n",
    "        x = rearrange(self.dropout(self.encoder(x)), \"b c n -> b n c\") \n",
    "        x = self.downsample(x).view(b,t,32,-1) #b t 32 c\n",
    "        x = self.transformer(x,swap = True).view(b,t,-1,256).mean(2)\n",
    "        x = self.time(x).mean(1)\n",
    "        x = self.mlp_head(x)\n",
    "        return x\n",
    "\n",
    "min_xyz = np.array([0.06372425, 0.05751023, -0.08976112]).reshape(1,1,3)\n",
    "max_xyz = np.array([0.63246971, 1.01475966, 0.14436169]).reshape(1,1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec067923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "def performance_metrics(test_y, y_pred):\n",
    "    test_dev = abs(test_y-y_pred)\n",
    "    mean_abs_dev = torch.mean(test_dev)\n",
    "    mae = mean_absolute_error(test_y, y_pred)\n",
    "    rms_dev = sqrt(mean_squared_error(y_pred, test_y))\n",
    "    mse = mean_squared_error(test_y,y_pred) \n",
    "    mape = mean_absolute_percentage_error(test_y, y_pred)\n",
    "    return mae, rms_dev, mse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a2dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,training_generator,test_generator,file):\n",
    "    \n",
    "    con = []      \n",
    "    net = TemporalModel()\n",
    "    net.cuda()\n",
    "    \n",
    "    lr = 0.0005\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr,weight_decay= 0.0)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[299], gamma=0.1)\n",
    "    loss_func = torch.nn.HuberLoss(reduction='mean', delta= 0.1)\n",
    "    start_time = time.time()\n",
    "    best_accuracy = 500\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pred_label = []\n",
    "        true_label = []\n",
    "        number_batch = 0\n",
    "        for x, y in tqdm(training_generator, desc=f\"Epoch {epoch}/{epochs-1}\", ncols=60):\n",
    "            if torch.cuda.device_count() > 0:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            x = torch.unsqueeze(x, 1) \n",
    "#             print(x.size())\n",
    "            b,d,t,n,c = x.size()\n",
    "            x = x.view(-1,t,n,c)\n",
    "            pred = net(x)\n",
    "            loss = loss_func(pred,y)\n",
    "            \n",
    "            pred_label.append(pred)\n",
    "            true_label.append(y)\n",
    "            \n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            number_batch += 1\n",
    "            lr = lr_scheduler.get_last_lr()[0]\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        pred_label = torch.tensor(pred_label).flatten()\n",
    "        true_label = torch.tensor(true_label).flatten()\n",
    "#         print(true_label)\n",
    "#         print(pred_label)\n",
    "#         pred_label = torch.cat(pred_label,0)\n",
    "#         true_label = torch.cat(true_label,0)\n",
    "#         train_accuracy = torch.sum(pred_label == true_label).type(torch.FloatTensor) / true_label.size(0)\n",
    "\n",
    "        mae, rms_dev, mse, mape = performance_metrics(true_label, pred_label)\n",
    "    \n",
    "        output('Epoch: ' + 'train' + str(epoch) + \n",
    "              '| mae ' + str(mae) + \n",
    "              '| rms_dev: ' + str(rms_dev) +\n",
    "              '| mse: ' + str(mse) +\n",
    "                '| mape: ' + str(mape)\n",
    "              )\n",
    "        print('Epoch: ' + 'train' + str(epoch) + \n",
    "              '| mae ' + str(mae) + \n",
    "              '| rms_dev: ' + str(rms_dev) +\n",
    "              '| mse: ' + str(mse) +\n",
    "              '| mape: ' + str(mape)\n",
    "              )\n",
    "        net.eval()\n",
    "        pred_label = []\n",
    "        pred_avg   = []\n",
    "        true_label = []\n",
    "        with torch.no_grad():\n",
    "          for x, y in tqdm(test_generator, desc=f\"Epoch {epoch}/{epochs-1}\", ncols=60):\n",
    "\n",
    "              if torch.cuda.device_count() > 0:\n",
    "                  x = x.cuda()\n",
    "                  y = y.cuda()\n",
    "              x = torch.unsqueeze(x, 1)\n",
    "              b,d,t,n,c = x.size()\n",
    "              x = x.view(-1,t,n,c)\n",
    "              pred_y    = net(x)\n",
    "            ###commented to convert round\n",
    "#               pred_mean = (pred_y.view(b,d).mean(1,keepdim = True) >= 0.5).float().cpu().detach()\n",
    "#               pred_y    = ((pred_y).view(b,d).mean(1,keepdim = True) >= 0.5).float().cpu().detach()\n",
    "              pred_label.append(pred_y)\n",
    "#               pred_avg.append(pred_mean)\n",
    "              true_label.append(y.cpu())\n",
    "              \n",
    "#           pred_label = torch.cat(pred_label,0)\n",
    "# #           pred_avg   = torch.cat(pred_avg,0)  \n",
    "#           true_label = torch.cat(true_label,0)\n",
    "          \n",
    "          pred_label = torch.tensor(pred_label).flatten()\n",
    "          true_label = torch.tensor(true_label).flatten()\n",
    "#           print(true_label.size())\n",
    "#           print(pred_label.size())\n",
    "          mae, rms_dev, mse, mape = performance_metrics(true_label, pred_label)\n",
    "#           test_accuracy = torch.sum(pred_label == true_label).type(torch.FloatTensor) / true_label.size(0)\n",
    "#           test_avg      = torch.sum(pred_avg   == true_label).type(torch.FloatTensor) / true_label.size(0)\n",
    "          con.append([epoch,mae])\n",
    "          output('test accuracy: ' + \n",
    "              '| mae ' + str(mae) + \n",
    "              '| rms_dev: ' + str(rms_dev) +\n",
    "              '| mse: ' + str(mse) +\n",
    "              '| mape: ' + str(mape)\n",
    "              )\n",
    "          print(Fore.GREEN + 'test accuracy: ' + \n",
    "              '| mae ' + str(mae) + \n",
    "              '| rms_dev: ' + str(rms_dev) +\n",
    "              '| mse: ' + str(mse) +\n",
    "              '| mape: ' + str(mape)\n",
    "              )\n",
    "\n",
    "          if mae < best_accuracy:\n",
    "              filepath = f\"{file}-{epoch:}-{loss}-{mae}.pt\"\n",
    "              torch.save(net.state_dict(), filepath)\n",
    "            #   torch.save(net, filepath)\n",
    "            #   test_frames(f'{test_accuracy}={test_f}')\n",
    "              print(\"Better Results Achieved!!!!!!!!!!!!\")\n",
    "              best_accuracy = mae\n",
    "\n",
    "        net.train()\n",
    "        \n",
    "        output(f\"ETA Per Epoch:{(time.time() - start_time) / (epoch + 1)}\")\n",
    "        # print(f\"ETA Per Epoch:{(time.time() - start_time) / (epoch + 1)}\")\n",
    "\n",
    "    best_v = max(con,key = lambda x:x[1])\n",
    "    global perf\n",
    "    perf += f\"best accruacy is {best_v[1]} in epoch {best_v[0]}\" + \"\\n\"\n",
    "    output(perf)\n",
    "    \n",
    "    \n",
    "# image_size = 48\n",
    "# label_path = \"labels\"\n",
    "# data = \"npy\"\n",
    "\n",
    "# sometimes = lambda aug: va.Sometimes(0.5, aug)\n",
    "# seq = va.Sequential([\n",
    "#     va.RandomCrop(size=(image_size, image_size)),       \n",
    "#     sometimes(va.HorizontalFlip()),              \n",
    "# ])\n",
    "\n",
    "\n",
    "# label_path = \"labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8577365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Add the arguments\n",
    "    ####################Parser not working###########################\n",
    "    ex = \"Kimore_ex5\"\n",
    "    lr = 0.0001\n",
    "    epoch = 1000\n",
    "    batch_size = 10\n",
    "    ####################Parser not working###########################\n",
    "\n",
    "    # my_parser.add_argument('--ex', type=str, default=\"Kimore_ex5\",\n",
    "    #                        help='the name of exercise.', required=True)\n",
    "    # my_parser.add_argument('--lr', type=int, default= 0.0001,\n",
    "    #                        help='initial learning rate for optimizer.')\n",
    "    # my_parser.add_argument('--epoch', type=int, default= 1000,\n",
    "    #                        help='number of epochs to train.')\n",
    "    # my_parser.add_argument('--batch_size', type=int, default= 10,\n",
    "    #                        help='training batch size.')\n",
    "    # args = my_parser.parse_args()\n",
    "    data_loader = Data_Loader(ex) \n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data_loader.scaled_x, data_loader.scaled_y, test_size=0.2, \n",
    "                                                        random_state = random_seed)\n",
    "    global output\n",
    "    def output(s):\n",
    "        with open(f\"log_{ex}\",\"a\") as f:\n",
    "            f.write(str(s) + \"\\n\")\n",
    "    print(train_x.shape)\n",
    "    print(train_y.shape)\n",
    "\n",
    "    train_x = torch.Tensor(train_x)\n",
    "    train_y = torch.Tensor(train_y)\n",
    "    test_x  = torch.Tensor(test_x)\n",
    "    test_y = torch.Tensor(test_y)\n",
    "    dataset = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    training_generator = torch.utils.data.DataLoader(dataset, batch_size = 1, shuffle = True, num_workers = 2)\n",
    "    dataset = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "    test_generator = torch.utils.data.DataLoader(dataset, batch_size = 1, shuffle = False, num_workers = 1)\n",
    "    current_path = './models/'\n",
    "    train(epoch,training_generator,test_generator,current_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0921b92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 100, 25, 3)\n",
      "(298, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/999: 100%|████████| 298/298 [03:19<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train0| mae 0.9427336| rms_dev: 1.1870208576686962| mse: 1.4090185| mape: 372.0898628234863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/999: 100%|██████████| 75/75 [00:28<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 1.0014786| rms_dev: 1.215198820667561| mse: 1.4767082| mape: 225.1978874206543\n",
      "Better Results Achieved!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/999: 100%|████████| 298/298 [04:56<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train1| mae 0.7689038| rms_dev: 0.9672708601764095| mse: 0.9356129| mape: 238.6246919631958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/999: 100%|██████████| 75/75 [00:35<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.9317725| rms_dev: 1.0997208696285148| mse: 1.209386| mape: 163.5643720626831\n",
      "Better Results Achieved!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/999: 100%|████████| 298/298 [06:20<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train2| mae 0.8112341| rms_dev: 1.003789160167646| mse: 1.0075927| mape: 294.44541931152344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/999: 100%|██████████| 75/75 [00:35<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.87242603| rms_dev: 1.0557954408268624| mse: 1.114704| mape: 144.19289827346802\n",
      "Better Results Achieved!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/999: 100%|████████| 298/298 [06:37<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train3| mae 0.73647606| rms_dev: 0.9272866544043111| mse: 0.85986054| mape: 202.5636911392212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/999: 100%|██████████| 75/75 [00:33<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 1.3012235| rms_dev: 1.612813886506228| mse: 2.6011686| mape: 405.95765113830566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/999: 100%|████████| 298/298 [05:00<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train4| mae 0.85069525| rms_dev: 1.040431275535705| mse: 1.0824972| mape: 277.1026372909546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/999: 100%|██████████| 75/75 [00:31<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.98073274| rms_dev: 1.194443081083678| mse: 1.4266943| mape: 249.2889404296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/999: 100%|████████| 298/298 [05:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train5| mae 0.824795| rms_dev: 1.0619226457797253| mse: 1.1276797| mape: 224.38502311706543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/999: 100%|██████████| 75/75 [00:31<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.904888| rms_dev: 1.045783655473629| mse: 1.0936635| mape: 170.5233335494995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/999: 100%|████████| 298/298 [04:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train6| mae 0.7960448| rms_dev: 1.002519830236487| mse: 1.005046| mape: 218.16675662994385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/999: 100%|██████████| 75/75 [00:30<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.8164193| rms_dev: 1.0194485217909965| mse: 1.0392753| mape: 124.46644306182861\n",
      "Better Results Achieved!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/999: 100%|████████| 298/298 [05:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train7| mae 0.8200348| rms_dev: 1.017871777708923| mse: 1.036063| mape: 224.65758323669434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/999: 100%|██████████| 75/75 [00:30<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.80631155| rms_dev: 1.0086567026550883| mse: 1.0173883| mape: 131.53107166290283\n",
      "Better Results Achieved!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/999: 100%|████████| 298/298 [05:07<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train8| mae 0.84527117| rms_dev: 1.0574946592299777| mse: 1.118295| mape: 219.89703178405762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/999: 100%|██████████| 75/75 [00:33<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.81920964| rms_dev: 0.9803586495273993| mse: 0.9611031| mape: 102.53973007202148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/999: 100%|████████| 298/298 [05:14<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: train9| mae 0.7973256| rms_dev: 0.9975021279104381| mse: 0.9950105| mape: 156.5334916114807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/999: 100%|██████████| 75/75 [00:34<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: | mae 0.8565474| rms_dev: 1.0441031127082425| mse: 1.0901513| mape: 127.14672088623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/999:  36%|██▍    | 106/298 [01:54<03:07,  1.02it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30921796",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros(100, 25, 21)\n",
    "idx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e15b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[:,:,1:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeError: mean() received an invalid combination of arguments - got (axis=NoneType, dtype=NoneType, out=NoneType, ), but expected one of:\n",
    " * (*, torch.dtype dtype)\n",
    " * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n",
    " * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.tensor([1,2,3,4,5,6], dtype = torch.float32)\n",
    "y_pred = torch.tensor([1.5,2.5,3.5,4.5,5.5,6.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "def performance_metrics(test_y, y_pred):\n",
    "    test_dev = abs(test_y-y_pred)\n",
    "#     print(test_dev)\n",
    "    mean_abs_dev = torch.mean(test_dev)\n",
    "    print(mean_abs_dev)\n",
    "    mae = mean_absolute_error(test_y, y_pred)\n",
    "    rms_dev = sqrt(mean_squared_error(y_pred, test_y))\n",
    "    mse = mean_squared_error(test_y,y_pred) \n",
    "    mape = mean_absolute_percentage_error(test_y, y_pred)\n",
    "    return mae, rms_dev, mse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2152be",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e31fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
